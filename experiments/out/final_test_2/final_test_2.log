attention: true
attention_size: 10
averaging: false
batch_size: 512
bidirectional: true
cell_kwargs: {}
cell_type: LSTM
class_weights: [1.0, 9.58871448, 1.810155, 31.99581504, 1.94160208, 10.88540896]
clip_gradients: false
dropout: true
embed_size: 300
exp_name: final_test_2
keep_prob: 0.5
lr: 0.0005
max_comment_size: 250
max_grad_norm: 5
n_epochs: 25
n_labels: 6
n_layers: 2
sparsemax: false
state_size: 128
2018-03-15 01:43:33 -- 
2018-03-15 01:43:33 -- Initializing...
2018-03-15 01:43:33 -- Training...
2018-03-15 01:43:33 -- Building model...
2018-03-15 01:43:35 -- Training model...
2018-03-15 01:45:25 -- 
2018-03-15 01:45:25 -- Epoch = 1/25:
2018-03-15 01:50:51 -- grad norm = 0.0844
2018-03-15 01:50:51 -- train loss = 0.0585
2018-03-15 01:50:51 -- dev loss = 0.0307
2018-03-15 01:50:51 -- train ROC AUC = 0.9373
2018-03-15 01:50:51 -- dev ROC AUC = 0.9355
2018-03-15 01:50:51 -- New best dev ROC AUC = 0.9355
2018-03-15 01:50:51 -- Saving new best model...
2018-03-15 01:50:53 -- 
2018-03-15 01:50:53 -- Epoch = 2/25:
2018-03-15 01:56:19 -- grad norm = 0.0633
2018-03-15 01:56:19 -- train loss = 0.0284
2018-03-15 01:56:19 -- dev loss = 0.0242
2018-03-15 01:56:19 -- train ROC AUC = 0.9758
2018-03-15 01:56:19 -- dev ROC AUC = 0.9723
2018-03-15 01:56:19 -- New best dev ROC AUC = 0.9723
2018-03-15 01:56:19 -- Saving new best model...
2018-03-15 01:56:39 -- 
2018-03-15 01:56:39 -- Epoch = 3/25:
2018-03-15 02:02:06 -- grad norm = 0.0838
2018-03-15 02:02:06 -- train loss = 0.0245
2018-03-15 02:02:06 -- dev loss = 0.0237
2018-03-15 02:02:06 -- train ROC AUC = 0.9779
2018-03-15 02:02:06 -- dev ROC AUC = 0.9724
2018-03-15 02:02:06 -- New best dev ROC AUC = 0.9724
2018-03-15 02:02:06 -- Saving new best model...
2018-03-15 02:02:24 -- 
2018-03-15 02:02:24 -- Epoch = 4/25:
2018-03-15 02:07:52 -- grad norm = 0.0488
2018-03-15 02:07:52 -- train loss = 0.0216
2018-03-15 02:07:52 -- dev loss = 0.0210
2018-03-15 02:07:52 -- train ROC AUC = 0.9858
2018-03-15 02:07:52 -- dev ROC AUC = 0.9794
2018-03-15 02:07:52 -- New best dev ROC AUC = 0.9794
2018-03-15 02:07:52 -- Saving new best model...
2018-03-15 02:08:09 -- 
2018-03-15 02:08:09 -- Epoch = 5/25:
2018-03-15 02:13:38 -- grad norm = 0.0575
2018-03-15 02:13:38 -- train loss = 0.0191
2018-03-15 02:13:38 -- dev loss = 0.0208
2018-03-15 02:13:38 -- train ROC AUC = 0.9883
2018-03-15 02:13:38 -- dev ROC AUC = 0.9807
2018-03-15 02:13:38 -- New best dev ROC AUC = 0.9807
2018-03-15 02:13:38 -- Saving new best model...
2018-03-15 02:13:56 -- 
2018-03-15 02:13:56 -- Epoch = 6/25:
2018-03-15 02:19:26 -- grad norm = 0.0515
2018-03-15 02:19:26 -- train loss = 0.0169
2018-03-15 02:19:26 -- dev loss = 0.0209
2018-03-15 02:19:26 -- train ROC AUC = 0.9896
2018-03-15 02:19:26 -- dev ROC AUC = 0.9788
2018-03-15 02:19:26 -- 
2018-03-15 02:19:26 -- Epoch = 7/25:
2018-03-15 02:24:56 -- grad norm = 0.0532
2018-03-15 02:24:56 -- train loss = 0.0150
2018-03-15 02:24:56 -- dev loss = 0.0200
2018-03-15 02:24:56 -- train ROC AUC = 0.9925
2018-03-15 02:24:56 -- dev ROC AUC = 0.9824
2018-03-15 02:24:56 -- New best dev ROC AUC = 0.9824
2018-03-15 02:24:56 -- Saving new best model...
2018-03-15 02:25:15 -- 
2018-03-15 02:25:15 -- Epoch = 8/25:
2018-03-15 02:30:47 -- grad norm = 0.0595
2018-03-15 02:30:47 -- train loss = 0.0139
2018-03-15 02:30:47 -- dev loss = 0.0211
2018-03-15 02:30:47 -- train ROC AUC = 0.9930
2018-03-15 02:30:47 -- dev ROC AUC = 0.9815
2018-03-15 02:30:47 -- 
2018-03-15 02:30:47 -- Epoch = 9/25:
2018-03-15 02:36:20 -- grad norm = 0.0490
2018-03-15 02:36:20 -- train loss = 0.0127
2018-03-15 02:36:20 -- dev loss = 0.0209
2018-03-15 02:36:20 -- train ROC AUC = 0.9942
2018-03-15 02:36:20 -- dev ROC AUC = 0.9816
2018-03-15 02:36:20 -- 
2018-03-15 02:36:20 -- Epoch = 10/25:
2018-03-15 02:41:54 -- grad norm = 0.0493
2018-03-15 02:41:54 -- train loss = 0.0115
2018-03-15 02:41:54 -- dev loss = 0.0228
2018-03-15 02:41:54 -- train ROC AUC = 0.9946
2018-03-15 02:41:54 -- dev ROC AUC = 0.9797
2018-03-15 02:41:54 -- 
2018-03-15 02:41:54 -- Epoch = 11/25:
2018-03-15 02:47:28 -- grad norm = 0.0440
2018-03-15 02:47:28 -- train loss = 0.0107
2018-03-15 02:47:28 -- dev loss = 0.0231
2018-03-15 02:47:28 -- train ROC AUC = 0.9952
2018-03-15 02:47:28 -- dev ROC AUC = 0.9806
2018-03-15 02:47:28 -- 
2018-03-15 02:47:28 -- Epoch = 12/25:
2018-03-15 02:53:04 -- grad norm = 0.0390
2018-03-15 02:53:04 -- train loss = 0.0099
2018-03-15 02:53:04 -- dev loss = 0.0239
2018-03-15 02:53:04 -- train ROC AUC = 0.9957
2018-03-15 02:53:04 -- dev ROC AUC = 0.9791
2018-03-15 02:53:04 -- 
2018-03-15 02:53:04 -- Epoch = 13/25:
2018-03-15 02:58:44 -- grad norm = 0.0396
2018-03-15 02:58:44 -- train loss = 0.0091
2018-03-15 02:58:44 -- dev loss = 0.0253
2018-03-15 02:58:44 -- train ROC AUC = 0.9960
2018-03-15 02:58:44 -- dev ROC AUC = 0.9778
2018-03-15 02:58:44 -- 
2018-03-15 02:58:44 -- Epoch = 14/25:
2018-03-15 03:04:25 -- grad norm = 0.0438
2018-03-15 03:04:25 -- train loss = 0.0086
2018-03-15 03:04:25 -- dev loss = 0.0280
2018-03-15 03:04:25 -- train ROC AUC = 0.9961
2018-03-15 03:04:25 -- dev ROC AUC = 0.9759
2018-03-15 03:04:25 -- 
2018-03-15 03:04:25 -- Epoch = 15/25:
2018-03-15 03:10:06 -- grad norm = 0.0487
2018-03-15 03:10:06 -- train loss = 0.0084
2018-03-15 03:10:06 -- dev loss = 0.0271
2018-03-15 03:10:06 -- train ROC AUC = 0.9960
2018-03-15 03:10:06 -- dev ROC AUC = 0.9764
2018-03-15 03:10:06 -- 
2018-03-15 03:10:06 -- Epoch = 16/25:
2018-03-15 03:15:48 -- grad norm = 0.0447
2018-03-15 03:15:48 -- train loss = 0.0081
2018-03-15 03:15:48 -- dev loss = 0.0273
2018-03-15 03:15:48 -- train ROC AUC = 0.9968
2018-03-15 03:15:48 -- dev ROC AUC = 0.9771
2018-03-15 03:15:48 -- 
2018-03-15 03:15:48 -- Epoch = 17/25:
2018-03-15 03:21:32 -- grad norm = 0.0330
2018-03-15 03:21:32 -- train loss = 0.0072
2018-03-15 03:21:32 -- dev loss = 0.0293
2018-03-15 03:21:32 -- train ROC AUC = 0.9972
2018-03-15 03:21:32 -- dev ROC AUC = 0.9765
2018-03-15 03:21:32 -- 
2018-03-15 03:21:32 -- Epoch = 18/25:
2018-03-15 03:27:18 -- grad norm = 0.0346
2018-03-15 03:27:18 -- train loss = 0.0067
2018-03-15 03:27:18 -- dev loss = 0.0304
2018-03-15 03:27:18 -- train ROC AUC = 0.9974
2018-03-15 03:27:18 -- dev ROC AUC = 0.9764
2018-03-15 03:27:18 -- 
2018-03-15 03:27:18 -- Epoch = 19/25:
2018-03-15 03:33:10 -- grad norm = 0.0378
2018-03-15 03:33:10 -- train loss = 0.0064
2018-03-15 03:33:10 -- dev loss = 0.0306
2018-03-15 03:33:10 -- train ROC AUC = 0.9976
2018-03-15 03:33:10 -- dev ROC AUC = 0.9760
2018-03-15 03:33:10 -- 
2018-03-15 03:33:10 -- Epoch = 20/25:
2018-03-15 03:39:05 -- grad norm = 0.0357
2018-03-15 03:39:05 -- train loss = 0.0061
2018-03-15 03:39:05 -- dev loss = 0.0326
2018-03-15 03:39:05 -- train ROC AUC = 0.9978
2018-03-15 03:39:05 -- dev ROC AUC = 0.9746
2018-03-15 03:39:05 -- 
2018-03-15 03:39:05 -- Epoch = 21/25:
2018-03-15 03:45:01 -- grad norm = 0.0519
2018-03-15 03:45:01 -- train loss = 0.0069
2018-03-15 03:45:01 -- dev loss = 0.0313
2018-03-15 03:45:01 -- train ROC AUC = 0.9977
2018-03-15 03:45:01 -- dev ROC AUC = 0.9741
2018-03-15 03:45:01 -- 
2018-03-15 03:45:01 -- Epoch = 22/25:
2018-03-15 03:50:59 -- grad norm = 0.0303
2018-03-15 03:50:59 -- train loss = 0.0056
2018-03-15 03:50:59 -- dev loss = 0.0340
2018-03-15 03:50:59 -- train ROC AUC = 0.9981
2018-03-15 03:50:59 -- dev ROC AUC = 0.9741
2018-03-15 03:50:59 -- 
2018-03-15 03:50:59 -- Epoch = 23/25:
2018-03-15 03:57:00 -- grad norm = 0.0354
2018-03-15 03:57:00 -- train loss = 0.0053
2018-03-15 03:57:00 -- dev loss = 0.0343
2018-03-15 03:57:00 -- train ROC AUC = 0.9981
2018-03-15 03:57:00 -- dev ROC AUC = 0.9737
2018-03-15 03:57:00 -- 
2018-03-15 03:57:00 -- Epoch = 24/25:
2018-03-15 04:02:57 -- grad norm = 0.0357
2018-03-15 04:02:57 -- train loss = 0.0051
2018-03-15 04:02:57 -- dev loss = 0.0354
2018-03-15 04:02:57 -- train ROC AUC = 0.9983
2018-03-15 04:02:57 -- dev ROC AUC = 0.9734
2018-03-15 04:02:57 -- 
2018-03-15 04:02:57 -- Epoch = 25/25:
2018-03-15 04:08:57 -- grad norm = 0.0333
2018-03-15 04:08:57 -- train loss = 0.0048
2018-03-15 04:08:57 -- dev loss = 0.0365
2018-03-15 04:08:57 -- train ROC AUC = 0.9984
2018-03-15 04:08:57 -- dev ROC AUC = 0.9730
2018-03-15 04:08:57 -- 
2018-03-15 04:08:57 -- Testing...
2018-03-15 04:08:57 -- Rebuilding model...
2018-03-15 04:09:02 -- Restoring best model...
2018-03-15 04:09:29 -- Restoring parameters from out/final_test_2/final_test_2.weights
2018-03-15 04:09:30 -- Predicting labels for test set...
2018-03-15 04:13:03 -- Saving test prediction...
2018-03-15 04:13:04 -- 
2018-03-15 04:13:04 -- Evaluating...
2018-03-15 04:13:05 -- Mean column-wise ROC AUC - train = 0.9925
2018-03-15 04:13:05 -- Mean column-wise ROC AUC - dev = 0.9824
2018-03-15 04:13:05 -- ROC AUC of toxic - train = 0.9862
2018-03-15 04:13:05 -- ROC AUC of toxic - dev = 0.9704
2018-03-15 04:13:05 -- ROC AUC of severe_toxic - train = 0.9932
2018-03-15 04:13:05 -- ROC AUC of severe_toxic - dev = 0.9898
2018-03-15 04:13:05 -- ROC AUC of obscene - train = 0.9933
2018-03-15 04:13:06 -- ROC AUC of obscene - dev = 0.9876
2018-03-15 04:13:06 -- ROC AUC of threat - train = 0.9992
2018-03-15 04:13:06 -- ROC AUC of threat - dev = 0.9895
2018-03-15 04:13:06 -- ROC AUC of insult - train = 0.9892
2018-03-15 04:13:06 -- ROC AUC of insult - dev = 0.9822
2018-03-15 04:13:06 -- ROC AUC of identity_hate - train = 0.9939
2018-03-15 04:13:06 -- ROC AUC of identity_hate - dev = 0.9747
2018-03-15 04:13:07 -- Mean column-wise average precision - train = 0.7776
2018-03-15 04:13:07 -- Mean column-wise average precision - dev = 0.6315
2018-03-15 04:13:07 -- average precision of toxic - train = 0.9165
2018-03-15 04:13:07 -- average precision of toxic - dev = 0.8649
2018-03-15 04:13:07 -- average precision of severe_toxic - train = 0.5350
2018-03-15 04:13:07 -- average precision of severe_toxic - dev = 0.5098
2018-03-15 04:13:07 -- average precision of obscene - train = 0.9060
2018-03-15 04:13:07 -- average precision of obscene - dev = 0.8683
2018-03-15 04:13:07 -- average precision of threat - train = 0.8561
2018-03-15 04:13:07 -- average precision of threat - dev = 0.4105
2018-03-15 04:13:07 -- average precision of insult - train = 0.8089
2018-03-15 04:13:07 -- average precision of insult - dev = 0.7692
2018-03-15 04:13:08 -- average precision of identity_hate - train = 0.6433
2018-03-15 04:13:08 -- average precision of identity_hate - dev = 0.3666
