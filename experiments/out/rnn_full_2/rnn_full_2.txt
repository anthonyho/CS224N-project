batch_size: 1024
bidirectional: false
cell_kwargs: {}
cell_type: LSTM
dropout: true
dropout_kwargs: {input_keep_prob: 0.8, output_keep_prob: 0.8, state_keep_prob: 0.8}
embed_size: 100
exp_name: rnn_full_2
label_names: [toxic, severe_toxic, obscene, threat, insult, identity_hate]
lr: 0.001
max_comment_size: 250
n_epochs: 50
n_features: 100
n_labels: 6
n_layers: 2
state_size: 100

Final loss = 0.0125
Mean column-wise ROC AUC - train = 0.9988
Mean column-wise ROC AUC - dev = 0.9613
ROC AUC of toxic - train = 0.9991
ROC AUC of toxic - dev = 0.9388
ROC AUC of severe_toxic - train = 0.9973
ROC AUC of severe_toxic - dev = 0.9820
ROC AUC of obscene - train = 0.9995
ROC AUC of obscene - dev = 0.9650
ROC AUC of threat - train = 0.9991
ROC AUC of threat - dev = 0.9679
ROC AUC of insult - train = 0.9989
ROC AUC of insult - dev = 0.9564
ROC AUC of identity_hate - train = 0.9988
ROC AUC of identity_hate - dev = 0.9581
Mean column-wise average precision - train = 0.9232
Mean column-wise average precision - dev = 0.5675
average precision of toxic - train = 0.9931
average precision of toxic - dev = 0.7956
average precision of severe_toxic - train = 0.8022
average precision of severe_toxic - dev = 0.3913
average precision of obscene - train = 0.9908
average precision of obscene - dev = 0.7923
average precision of threat - train = 0.8642
average precision of threat - dev = 0.3313
average precision of insult - train = 0.9756
average precision of insult - dev = 0.6726
average precision of identity_hate - train = 0.9134
average precision of identity_hate - dev = 0.4221
