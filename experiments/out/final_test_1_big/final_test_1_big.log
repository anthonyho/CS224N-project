attention: true
attention_size: 10
averaging: false
batch_size: 128
bidirectional: true
cell_kwargs: {}
cell_type: LSTM
class_weights: [1.0, 9.58871448, 1.810155, 31.99581504, 1.94160208, 10.88540896]
clip_gradients: false
dropout: true
embed_size: 300
exp_name: final_test_1_big
keep_prob: 0.5
lr: 0.0005
max_comment_size: 250
max_grad_norm: 5
n_epochs: 20
n_labels: 6
n_layers: 1
sparsemax: false
state_size: 512
2018-03-16 05:50:00 -- 
2018-03-16 05:50:00 -- Initializing...
2018-03-16 05:50:00 -- Training...
2018-03-16 05:50:00 -- Building model...
2018-03-16 05:50:03 -- Training model...
2018-03-16 05:51:54 -- 
2018-03-16 05:51:54 -- Epoch = 1/20:
2018-03-16 06:07:47 -- grad norm = 0.0652
2018-03-16 06:07:47 -- train loss = 0.0357
2018-03-16 06:07:47 -- dev loss = 0.0235
2018-03-16 06:07:47 -- train ROC AUC = 0.9786
2018-03-16 06:07:47 -- dev ROC AUC = 0.9758
2018-03-16 06:07:47 -- New best dev ROC AUC = 0.9758
2018-03-16 06:07:47 -- Saving new best model...
2018-03-16 06:07:50 -- 
2018-03-16 06:07:50 -- Epoch = 2/20:
2018-03-16 06:24:01 -- grad norm = 0.0414
2018-03-16 06:24:01 -- train loss = 0.0206
2018-03-16 06:24:01 -- dev loss = 0.0192
2018-03-16 06:24:01 -- train ROC AUC = 0.9884
2018-03-16 06:24:01 -- dev ROC AUC = 0.9847
2018-03-16 06:24:01 -- New best dev ROC AUC = 0.9847
2018-03-16 06:24:01 -- Saving new best model...
2018-03-16 06:24:19 -- 
2018-03-16 06:24:19 -- Epoch = 3/20:
2018-03-16 06:40:53 -- grad norm = 0.0380
2018-03-16 06:40:53 -- train loss = 0.0172
2018-03-16 06:40:53 -- dev loss = 0.0188
2018-03-16 06:40:53 -- train ROC AUC = 0.9903
2018-03-16 06:40:53 -- dev ROC AUC = 0.9851
2018-03-16 06:40:53 -- New best dev ROC AUC = 0.9851
2018-03-16 06:40:53 -- Saving new best model...
2018-03-16 06:41:12 -- 
2018-03-16 06:41:12 -- Epoch = 4/20:
2018-03-16 06:58:14 -- grad norm = 0.0339
2018-03-16 06:58:14 -- train loss = 0.0149
2018-03-16 06:58:14 -- dev loss = 0.0186
2018-03-16 06:58:14 -- train ROC AUC = 0.9929
2018-03-16 06:58:14 -- dev ROC AUC = 0.9855
2018-03-16 06:58:14 -- New best dev ROC AUC = 0.9855
2018-03-16 06:58:14 -- Saving new best model...
2018-03-16 06:58:33 -- 
2018-03-16 06:58:33 -- Epoch = 5/20:
2018-03-16 07:15:55 -- grad norm = 0.0303
2018-03-16 07:15:55 -- train loss = 0.0129
2018-03-16 07:15:55 -- dev loss = 0.0192
2018-03-16 07:15:55 -- train ROC AUC = 0.9944
2018-03-16 07:15:55 -- dev ROC AUC = 0.9851
2018-03-16 07:15:55 -- 
2018-03-16 07:15:55 -- Epoch = 6/20:
2018-03-16 07:33:42 -- grad norm = 0.0271
2018-03-16 07:33:42 -- train loss = 0.0113
2018-03-16 07:33:42 -- dev loss = 0.0206
2018-03-16 07:33:42 -- train ROC AUC = 0.9954
2018-03-16 07:33:42 -- dev ROC AUC = 0.9835
2018-03-16 07:33:42 -- 
2018-03-16 07:33:42 -- Epoch = 7/20:
2018-03-16 07:51:56 -- grad norm = 0.0248
2018-03-16 07:51:56 -- train loss = 0.0099
2018-03-16 07:51:56 -- dev loss = 0.0217
2018-03-16 07:51:56 -- train ROC AUC = 0.9962
2018-03-16 07:51:56 -- dev ROC AUC = 0.9817
2018-03-16 07:51:56 -- 
2018-03-16 07:51:56 -- Epoch = 8/20:
2018-03-16 08:10:34 -- grad norm = 0.0223
2018-03-16 08:10:34 -- train loss = 0.0087
2018-03-16 08:10:34 -- dev loss = 0.0243
2018-03-16 08:10:34 -- train ROC AUC = 0.9968
2018-03-16 08:10:34 -- dev ROC AUC = 0.9785
2018-03-16 08:10:34 -- 
2018-03-16 08:10:34 -- Epoch = 9/20:
2018-03-16 08:29:38 -- grad norm = 0.0208
2018-03-16 08:29:38 -- train loss = 0.0077
2018-03-16 08:29:38 -- dev loss = 0.0259
2018-03-16 08:29:38 -- train ROC AUC = 0.9974
2018-03-16 08:29:38 -- dev ROC AUC = 0.9774
2018-03-16 08:29:38 -- 
2018-03-16 08:29:38 -- Epoch = 10/20:
2018-03-16 08:49:02 -- grad norm = 0.0188
2018-03-16 08:49:02 -- train loss = 0.0067
2018-03-16 08:49:02 -- dev loss = 0.0285
2018-03-16 08:49:02 -- train ROC AUC = 0.9978
2018-03-16 08:49:02 -- dev ROC AUC = 0.9766
2018-03-16 08:49:02 -- 
2018-03-16 08:49:02 -- Epoch = 11/20:
2018-03-16 09:08:53 -- grad norm = 0.0181
2018-03-16 09:08:53 -- train loss = 0.0062
2018-03-16 09:08:53 -- dev loss = 0.0307
2018-03-16 09:08:53 -- train ROC AUC = 0.9979
2018-03-16 09:08:53 -- dev ROC AUC = 0.9735
2018-03-16 09:08:53 -- 
2018-03-16 09:08:53 -- Epoch = 12/20:
2018-03-16 09:29:16 -- grad norm = 0.0185
2018-03-16 09:29:16 -- train loss = 0.0057
2018-03-16 09:29:16 -- dev loss = 0.0322
2018-03-16 09:29:16 -- train ROC AUC = 0.9984
2018-03-16 09:29:16 -- dev ROC AUC = 0.9727
2018-03-16 09:29:16 -- 
2018-03-16 09:29:16 -- Epoch = 13/20:
2018-03-16 09:50:03 -- grad norm = 0.0168
2018-03-16 09:50:03 -- train loss = 0.0051
2018-03-16 09:50:03 -- dev loss = 0.0336
2018-03-16 09:50:03 -- train ROC AUC = 0.9986
2018-03-16 09:50:03 -- dev ROC AUC = 0.9723
2018-03-16 09:50:03 -- 
2018-03-16 09:50:03 -- Epoch = 14/20:
2018-03-16 10:11:25 -- grad norm = 0.0148
2018-03-16 10:11:25 -- train loss = 0.0044
2018-03-16 10:11:25 -- dev loss = 0.0363
2018-03-16 10:11:25 -- train ROC AUC = 0.9988
2018-03-16 10:11:25 -- dev ROC AUC = 0.9692
2018-03-16 10:11:25 -- 
2018-03-16 10:11:25 -- Epoch = 15/20:
2018-03-16 10:33:17 -- grad norm = 0.0137
2018-03-16 10:33:17 -- train loss = 0.0040
2018-03-16 10:33:17 -- dev loss = 0.0380
2018-03-16 10:33:17 -- train ROC AUC = 0.9989
2018-03-16 10:33:17 -- dev ROC AUC = 0.9696
2018-03-16 10:33:17 -- 
2018-03-16 10:33:17 -- Epoch = 16/20:
2018-03-16 10:55:35 -- grad norm = 0.0132
2018-03-16 10:55:35 -- train loss = 0.0036
2018-03-16 10:55:35 -- dev loss = 0.0414
2018-03-16 10:55:35 -- train ROC AUC = 0.9991
2018-03-16 10:55:35 -- dev ROC AUC = 0.9656
2018-03-16 10:55:35 -- 
2018-03-16 10:55:35 -- Epoch = 17/20:
2018-03-16 11:18:17 -- grad norm = 0.0129
2018-03-16 11:18:17 -- train loss = 0.0033
2018-03-16 11:18:17 -- dev loss = 0.0419
2018-03-16 11:18:17 -- train ROC AUC = 0.9993
2018-03-16 11:18:17 -- dev ROC AUC = 0.9641
2018-03-16 11:18:17 -- 
2018-03-16 11:18:17 -- Epoch = 18/20:
2018-03-16 11:41:25 -- grad norm = 0.0121
2018-03-16 11:41:25 -- train loss = 0.0030
2018-03-16 11:41:25 -- dev loss = 0.0441
2018-03-16 11:41:25 -- train ROC AUC = 0.9994
2018-03-16 11:41:25 -- dev ROC AUC = 0.9613
2018-03-16 11:41:25 -- 
2018-03-16 11:41:25 -- Epoch = 19/20:
2018-03-16 12:05:01 -- grad norm = 0.0109
2018-03-16 12:05:01 -- train loss = 0.0026
2018-03-16 12:05:01 -- dev loss = 0.0471
2018-03-16 12:05:01 -- train ROC AUC = 0.9995
2018-03-16 12:05:01 -- dev ROC AUC = 0.9588
2018-03-16 12:05:01 -- 
2018-03-16 12:05:01 -- Epoch = 20/20:
2018-03-16 12:28:58 -- grad norm = 0.0112
2018-03-16 12:28:58 -- train loss = 0.0024
2018-03-16 12:28:58 -- dev loss = 0.0499
2018-03-16 12:28:58 -- train ROC AUC = 0.9996
2018-03-16 12:28:58 -- dev ROC AUC = 0.9588
2018-03-16 12:28:58 -- 
2018-03-16 12:28:58 -- Testing...
2018-03-16 12:28:58 -- Rebuilding model...
2018-03-16 12:29:00 -- Restoring best model...
2018-03-16 12:30:09 -- Restoring parameters from out/final_test_1_big/final_test_1_big.weights
2018-03-16 12:30:09 -- Predicting labels for test set...
2018-03-16 12:36:35 -- Saving test prediction...
2018-03-16 12:36:35 -- 
2018-03-16 12:36:35 -- Evaluating...
2018-03-16 12:36:37 -- Mean column-wise ROC AUC - train = 0.9929
2018-03-16 12:36:37 -- Mean column-wise ROC AUC - dev = 0.9855
2018-03-16 12:36:37 -- ROC AUC of toxic - train = 0.9861
2018-03-16 12:36:37 -- ROC AUC of toxic - dev = 0.9760
2018-03-16 12:36:37 -- ROC AUC of severe_toxic - train = 0.9934
2018-03-16 12:36:37 -- ROC AUC of severe_toxic - dev = 0.9899
2018-03-16 12:36:37 -- ROC AUC of obscene - train = 0.9936
2018-03-16 12:36:37 -- ROC AUC of obscene - dev = 0.9909
2018-03-16 12:36:37 -- ROC AUC of threat - train = 0.9992
2018-03-16 12:36:37 -- ROC AUC of threat - dev = 0.9899
2018-03-16 12:36:37 -- ROC AUC of insult - train = 0.9901
2018-03-16 12:36:37 -- ROC AUC of insult - dev = 0.9841
2018-03-16 12:36:38 -- ROC AUC of identity_hate - train = 0.9946
2018-03-16 12:36:38 -- ROC AUC of identity_hate - dev = 0.9822
2018-03-16 12:36:38 -- Mean column-wise average precision - train = 0.8172
2018-03-16 12:36:39 -- Mean column-wise average precision - dev = 0.6607
2018-03-16 12:36:39 -- average precision of toxic - train = 0.9159
2018-03-16 12:36:39 -- average precision of toxic - dev = 0.8787
2018-03-16 12:36:39 -- average precision of severe_toxic - train = 0.5800
2018-03-16 12:36:39 -- average precision of severe_toxic - dev = 0.4699
2018-03-16 12:36:39 -- average precision of obscene - train = 0.9182
2018-03-16 12:36:39 -- average precision of obscene - dev = 0.8986
2018-03-16 12:36:39 -- average precision of threat - train = 0.8821
2018-03-16 12:36:39 -- average precision of threat - dev = 0.4582
2018-03-16 12:36:39 -- average precision of insult - train = 0.8310
2018-03-16 12:36:39 -- average precision of insult - dev = 0.7805
2018-03-16 12:36:39 -- average precision of identity_hate - train = 0.7763
2018-03-16 12:36:39 -- average precision of identity_hate - dev = 0.4784
